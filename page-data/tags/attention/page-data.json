{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-tag-query-tsx","path":"/tags/attention/","result":{"data":{"allPost":{"nodes":[{"slug":"/blog/attention","title":"Attention Please!","date":"22.07.2024","excerpt":"Overview This article would discuss the following concepts\n\nBasic intuation of attention model Mathematics behind the attention model Impleâ€¦","timeToRead":6,"description":"Attention in machine learning is like the brain's spotlight, highlighting important parts of data. Introduced in 2014, it focuses on relevant information using \"queries,\" \"keys,\" and \"values.\" Imagine a model yelling, \"Hey, brain, remember that detail!\" to handle complex tasks like translating long sentences.","tags":[{"name":"CNN","slug":"cnn"},{"name":"Attention","slug":"attention"},{"name":"TensorFlow","slug":"tensor-flow"}]}]}},"pageContext":{"slug":"attention","name":"Attention","formatString":"DD.MM.YYYY"}},"staticQueryHashes":["2421966660","2744905544","3090400250"],"slicesMap":{}}